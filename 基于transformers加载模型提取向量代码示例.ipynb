{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fd3f3-9abb-449c-abbb-27916a69f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor,AutoModelForImageClassification,BeitFeatureExtractor, BeitModel\n",
    "from transformers import AutoFeatureExtractor, AutoModelForPreTraining\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c607d-3df2-4439-9afa-6fc8a60b66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载专利数据集\n",
    "import os\n",
    "def require_filename(path):\n",
    "    root = path\n",
    "    file_list = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for filepath in filenames:\n",
    "            file_list.append(os.path.join(dirpath, filepath))\n",
    "    return file_list\n",
    "file_list1 = require_filename('/home/jovyan/mnt/juicefs-share-bigdata-dip-ai/NLP/patent_pic/wgpic1')\n",
    "file_list = require_filename('/home/jovyan/mnt/juicefs-share-bigdata-dip-ai/NLP/patent_pic/wgpic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf149d27-9dc5-4f58-bb94-e8f60387778a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset = load_dataset(\"cifar10\")\n",
    "# image = dataset[\"test\"][\"image\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a9581-bab3-4957-9309-b6aef899fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = dataset['test']['img'][0]\n",
    "test_label = dataset['test']['label']\n",
    "dataset['test']['image'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30bd446-dda8-4f11-8d44-07278696071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型测试代码\n",
    "# feature_extractor = BeitFeatureExtractor.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k\")\n",
    "# model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224-pt22k\")\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d704d-8263-4aa7-9fb9-6b716561be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vec(image):\n",
    "    ls = {}\n",
    "    inputs = feature_extractor(image, return_tensors=\"pt\")\n",
    "    inputs = inputs.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        hidden_states = model(**inputs, return_dict=True, output_hidden_states=True).hidden_states\n",
    "        \n",
    "        output_hidden_state = (hidden_states[-1] + hidden_states[1]).mean(dim=1)\n",
    "        vec = output_hidden_state.cpu().numpy()[0]\n",
    "        ls['first_last_avg'] = vec\n",
    "        \n",
    "        output_hidden_state = (hidden_states[-1]).mean(dim=1)\n",
    "        vec = output_hidden_state.cpu().numpy()[0]\n",
    "        ls['last_avg'] = vec\n",
    "        \n",
    "        output_hidden_state = (hidden_states[-1] + hidden_states[-2]).mean(dim=1)\n",
    "        vec = output_hidden_state.cpu().numpy()[0]\n",
    "        ls['last2avg'] = vec\n",
    "        \n",
    "        output_hidden_state = (hidden_states[-1])[:, 0, :]\n",
    "        vec = output_hidden_state.cpu().numpy()[0]\n",
    "        ls['cls'] = vec\n",
    "        \n",
    "    return ls\n",
    "# 降维函数\n",
    "def compute_kernel_bias(vecs):\n",
    "    \"\"\"计算kernel和bias\n",
    "    最后的变换：y = (x + bias).dot(kernel)\n",
    "    \"\"\"\n",
    "#     vecs_ = np.concatenate(vecs, axis=0)\n",
    "    mu = vecs.mean(axis=0, keepdims=True)\n",
    "    cov = np.cov(vecs.T)\n",
    "    u, s, vh = np.linalg.svd(cov)\n",
    "    W = np.dot(u, np.diag(1 / np.sqrt(s)))\n",
    "    return W, -mu\n",
    "\n",
    "def transform_and_normalize(vecs, kernel=None, bias=None, dim=[]):\n",
    "    \"\"\"应用变换，然后标准化\n",
    "    \"\"\"\n",
    "    def std1(vecs_):\n",
    "        norms = (vecs_**2).sum(axis=1, keepdims=True)**0.5\n",
    "        return vecs_ / np.clip(norms, 1e-8, np.inf)\n",
    "    \n",
    "    res = []\n",
    "    if not (kernel is None or bias is None):\n",
    "        vecs = (vecs + bias).dot(kernel)\n",
    "#         res.append(std1(vecs)[0].round(6))\n",
    "        return vecs.round(6)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f7651-e162-4b77-8d41-c685066e7544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = image_to_vec(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4262a3-1bdf-4a72-bb80-e51d4eaa9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a10ab-1f0f-434c-855b-d74b278f17e3",
   "metadata": {},
   "source": [
    "cifar10计算向量，保存检索模型代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c2c3e-6826-4d14-9b88-fdab35759fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = 768  # 句向量维度\n",
    "# \n",
    "# 模型保存地址\n",
    "model_name_ls = []\n",
    "for model_name in [\"microsoft/beit-base-patch16-224-pt22k\"]:\n",
    "    # 加载模型\n",
    "    vec_ls = []\n",
    "    feature_extractor = BeitFeatureExtractor.from_pretrained(model_name)\n",
    "    model = BeitModel.from_pretrained(model_name)\n",
    "    model.cuda()\n",
    "    # 计算向量\n",
    "    for image_ in tqdm(dataset['test']['img']):\n",
    "        vec_ = image_to_vec(image_)\n",
    "        vec_ls.append(vec_)\n",
    "    for i in tqdm(['first_last_avg', 'last_avg', 'last2avg','cls']):\n",
    "        ls_vecs = [_[i] for _ in vec_ls]\n",
    "        #计算降维矩阵\n",
    "        ls_vecs_ = np.array(ls_vecs)\n",
    "        kernel, bias = compute_kernel_bias(ls_vecs_)\n",
    "        #分别构建检索模型\n",
    "        for j in [768, 128]:\n",
    "            m = 0\n",
    "            name_ = '%s_cifar10_%s_%s.ann' %(model_name.split('/')[1].split('-')[0], i, j)     \n",
    "            t_768 = AnnoyIndex(j)\n",
    "            t_768.on_disk_build(name_)\n",
    "            for vec_ in transform_and_normalize(ls_vecs_, kernel[:, :j], bias, []):\n",
    "                t_768.add_item(m, vec_)\n",
    "                m+=1\n",
    "            t_768.build(10)         \n",
    "#             model_name_ls.append(name_)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a01b09-00f2-4226-bb66-aa25a5abab02",
   "metadata": {},
   "source": [
    "专利图片计算向量，保存相似模型代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80763c-ccc5-4299-8c8b-e81f9edb48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 768  # 句向量维度\n",
    "file_ls = []\n",
    "# 模型保存地址\n",
    "model_name_ls = []\n",
    "# 测试代码，支持同时测试多个模型，多种向量降维长度，多种取向量方式\n",
    "# for model_name in [\"microsoft/beit-base-patch16-224-pt22k\"]:\n",
    "for model_name in [\"facebook/vit-mae-base\"]:    \n",
    "    # 加载模型\n",
    "    vec_ls = []\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "    model = AutoModelForPreTraining.from_pretrained(model_name)\n",
    "    model.cuda()\n",
    "    # 计算向量\n",
    "    for file in tqdm(file_list):\n",
    "        try:\n",
    "            image = Image.open(file)\n",
    "            image = image.resize((224, 224))  \n",
    "            vec_ = image_to_vec(image)\n",
    "        except:\n",
    "            continue\n",
    "#             image = Image.open(file).convert('RGB')\n",
    "#             image = image.resize((224, 224))\n",
    "        file_ls.append(file)\n",
    "        \n",
    "        vec_ls.append(vec_)\n",
    "    for i in tqdm(['first_last_avg', 'last_avg', 'last2avg','cls']):\n",
    "        ls_vecs = [_[i] for _ in vec_ls]\n",
    "        #计算降维矩阵\n",
    "        ls_vecs_ = np.array(ls_vecs)\n",
    "        kernel, bias = compute_kernel_bias(ls_vecs_)\n",
    "        #分别构建检索模型\n",
    "        for j in [768, 128]:\n",
    "            m = 0\n",
    "            name_ = '%s_patent_%s_%s.ann' %(model_name.split('/')[1].split('-')[1], i, j)     \n",
    "            t_768 = AnnoyIndex(j)\n",
    "            t_768.on_disk_build(name_)\n",
    "            for vec_ in transform_and_normalize(ls_vecs_, kernel[:, :j], bias, []):\n",
    "                t_768.add_item(m, vec_)\n",
    "                m+=1\n",
    "            t_768.build(10)         \n",
    "#             model_name_ls.append(name_)\n",
    "\n",
    "map_dict = {}\n",
    "m = 0\n",
    "for i in file_ls:\n",
    "    map_dict[m] = i\n",
    "    m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce05d6-ecf2-401a-98b5-2dac97671c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = t_768.get_nns_by_item(0, 2000,  include_distances=True)    \n",
    "score = [round(1-i**2/2, 4) for i in sim[1]]\n",
    "sim_label = [test_label[i] for i in sim[0]]\n",
    "sim_label.count(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41919248-3b46-46e8-8adb-7be05b601c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取所有保存的检索模型\n",
    "model = require_filename('./')\n",
    "# model = [i for i in model if 'patent' in i]\n",
    "# 只取mae模型的结果\n",
    "model = [i for i in model if 'mae' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38b03d-2c01-4179-b5e5-9b208c35d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载需要测试的模型，保存在列表\n",
    "model_ls = []\n",
    "for model_name in model:\n",
    "    f = int(model_name[-7:-4])\n",
    "    t_384 = AnnoyIndex(f)\n",
    "    t_384.load(model_name)\n",
    "    model_ls.append(t_384)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280c544-a8dc-403f-a6d2-3c57048c96c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./beit_patent_first_last_avg_128.ann\n",
    "# ./beit_patent_last_avg_128.ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225615d-33de-4a5e-a0d2-0c145f438cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3456，6549， 4354， 7346\n",
    "id_ = 4354\n",
    "for t_768, model_name in zip(model_ls, model):\n",
    "    print(model_name)\n",
    "    sim = t_768.get_nns_by_item(id_, 9,  include_distances=True)    \n",
    "        # 相似模型返回的distances是欧式距离，不方便观察相似性，将欧式距离转化为余弦相似度\n",
    "    sim = [[map_dict[i], str(round(1-j**2/2, 4))] for i, j in zip(sim[0], sim[1])]\n",
    "    m = 1\n",
    "    plt.figure()\n",
    "    for i in sim:\n",
    "        image = Image.open(i[0])\n",
    "        plt.subplot(3, 3, m)\n",
    "        plt.imshow(image)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(str(i[1]))\n",
    "        m+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“torch”",
   "language": "python",
   "name": "py36-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
